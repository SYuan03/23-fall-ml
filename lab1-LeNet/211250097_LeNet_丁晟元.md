## 1. 作业说明

**LeNet**

基于Pytorch实现LeNet-5 ，并完成CIFAR10识别。

可以尝试使用一些图像预处理技术（去噪，归一化，分割等），再使用神经网络进行特征提取。

同时可以对训练过程进行可视化处理，分析训练趋势。



## 2. 环境说明

Windows10 + Anaconda + PyTorch1.12.1(cpuonly)



## 3. 数据集

CIFAR10数据集：包含 60000 张 32 X 32 的 RGB 彩色图片，总共 10 个分类。其中，包括 50000 张用于训练集，10000 张用于测试集；

![image-20231017201924367](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231017201924367.png)



## 4. 理论说明

### LeNet-5模型

![image-20231017203707785](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231017203707785.png)

LeNet-5模型结构为**输入–卷积层–池化层–卷积层–池化层–全连接层–全连接层–输出**，为串联模式，如上图所示



## 5. 具体实现

### 5.1. 前置工作

安装pytorch cpu版本
``` bash
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cpuonly -c pytorch
```

![image-20231017205923082](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231017205923082.png)



下载数据集

![image-20231019105750004](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231019105750004.png)



### 5.2. 具体步骤分析

#### 1. 数据预处理

- 归一化：先使用np的函数计算了mean和std，再使用transform对数据集进行处理

  train_set的shape是(50000, 32, 32, 3)，分别是sample个数，图像的高，图像的宽，通道数

  处理之后将其载入DataLoader中，每次迭代都会返回一个batch_size的数据

  ``` python
  # 先下载数据集进行计算std和mean
  train_set = torchvision.datasets.CIFAR10(root='./dataset', train=True, download=True)
  mean = train_set.data.mean(axis=(0, 1, 2)) / 255
  std = train_set.data.std(axis=(0, 1, 2)) / 255
  print("mean:", mean)
  print("std:", std)
  
  transform = transforms.Compose(
      [transforms.ToTensor(),
       transforms.Normalize(mean, std)])
  
  # train_loader是一个可迭代对象，每次迭代都会返回一个batch_size的数据
  # num_workers表示用几个子进程来加载数据
  train_set = torchvision.datasets.CIFAR10(root='./dataset', train=True, download=True, transform=transform)
  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)
  
  # 下载并加载测试集
  test_set = torchvision.datasets.CIFAR10(root='./dataset', train=False, download=True, transform=transform)
  test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)
  ```

- 去噪：可以采用图像去噪算法，如高斯滤波器、中值滤波器等，以减少图像中的噪声对模型的干扰。  

  但该数据集是已经较为干净的数据集，所以不需要进行去噪处理。

#### 2. 建立模型LeNet模型

参照上文的模型结构图进行建立

``` python
# Step2 定义一个卷积神经网络
class MyNet(nn.Module):
    def __init__(self):
        super().__init__()
        in_channels = 3
        # 卷积层1
        # 参数分别是输入通道数，输出通道数，卷积核大小
        # in_channels指明了输入的通道数，这里是3，因为输入的是RGB图像
        # out_channels指明了输出的通道数，我们将从中提取18个特征
        self.conv1 = nn.Conv2d(in_channels, in_channels * 6, 5)

        # 池化层1
        # 参数分别是池化核大小，步长
        # 这表示使用最大池化操作，池化核的大小是2x2，步长也是2。这意味着在每次池化操作中，特征图被划分为2x2的区域，
        # 然后在每个区域内选择最大值作为输出。步长为2表示池化操作会每隔2个像素进行一次操作，不会重叠。
        # 池化层用于下采样，通过减小特征图的大小，保留最显著的特征，从而减少计算复杂性。
        self.pool1 = nn.MaxPool2d(2, 2)

        # 卷积层2
        # 这里的输入通道数是18，因为上一层的输出是18个特征图
        # 输出通道数是18，从中提取48个特征
        self.conv2 = nn.Conv2d(in_channels * 6, in_channels * 16, 5)

        # 池化层2
        # 其实这里的池化层和上面的池化层1是一样的
        # 经过该层后，每张图片对应 16 * 5 * 5 * 3个特征
        self.pool2 = nn.MaxPool2d(2, 2)

        # 全连接层1
        # 这里的输入是16*5*5*3
        self.fc1 = nn.Linear(16 * 5 * 5 * in_channels, 120 * in_channels)

        # 全连接层2
        # 这里的输入是120，输出是84
        self.fc2 = nn.Linear(120 * in_channels, 84 * in_channels)

        # 全连接层3
        # 这里的输入是84，输出是10
        self.fc3 = nn.Linear(84 * in_channels, 10)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))

        # x是一个4维的tensor，第一维是batch_size，第二维是通道数，第三维和第四维是图像的高和宽
        # 经过flatten操作后，x变成了2维的tensor，第一维是batch_size，第二维是通道数*图像的高*图像的宽
        # 因为下一层是全连接层（线性层），所以需要将图像展开成一维的
        x = torch.flatten(x, 1)  # flatten all dimensions except batch

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```

#### 3. 定义损失器和优化函数

``` python
# Step3 定义损失函数和优化器
# 交叉熵损失函数
criterion = nn.CrossEntropyLoss()
# 优化器，使用随机梯度下降算法，学习率为0.001，动量为0.9
# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)
optimizer = optim.Adam(net.parameters(), lr=LR)
```

#### 4. 训练及可视化

**迭代训练数据集**
在每个epoch中，使用`enumerate(train_loader, 0)`来获取训练数据集的迭代器，其中`train_loader`是已经加载好的训练数据集。然后使用一个循环来遍历每个batch的数据。

**前向传播和反向传播**
在每个batch中，首先将输入数据`inputs`输入到LeNet-5模型中进行前向传播，得到输出`outputs`。然后，计算模型的损失函数`loss`，例如交叉熵损失函数。接下来使用反向传播方法计算梯度，并通过调用`optimizer.step()`来更新模型的参数。

**计算训练损失**
在每个epoch的训练过程中，累加每个batch的损失值`loss.item()`到`running_loss`中，以便后续计算平均训练损失。这个损失值可以用来观察训练过程中的损失下降情况。

**测试模型准确率**
在每个epoch结束后，使用测试数据集对模型进行评估。通过将测试数据传入已经训练好的LeNet-5模型中，可以获得模型的输出`outputs`。然后，使用`torch.max()`函数找到输出中的最大值，并返回对应的索引，即预测的类别。将预测的类别与真实标签`labels`进行比较，并计算正确预测的数量。

``` py
# Step4 训练网络
for epoch in range(epochs):
    loop = tqdm.tqdm(
        enumerate(train_loader, 0),
        total=len(train_loader),
        desc=f'Epoch [{epoch + 1}/{epochs}]',
        ncols=100,
    )

    running_loss = 0.0
    # 获取训练数据
    for i, data in loop:
        inputs, labels = data
        # 梯度清零
        optimizer.zero_grad()
        # 前向传播
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        # 反向传播，计算梯度，更新参数
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    loop.set_postfix(loss=running_loss / len(train_loader))

    # 每1个epoch记录一次准确率
    correct = 0
    total = 0
    # 因为加载的模型是训练好的，所以不需要计算梯度
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            outputs = net(images)
            # torch.max()返回两个tensor，第一个tensor是最大值，第二个tensor是最大值的索引
            # 这里我们只需要索引
            _, predicted = torch.max(outputs.data, 1)
            # labels.size(0)是一个batch中label的个数，也就是4
            total += labels.size(0)
            # (predicted == labels)返回一个tensor，tensor中的元素是True或者False
            # tensor.sum()将True转化为1，False转化为0，然后求和
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total  # 不需要使用 //，以保留小数
    formatted_accuracy = f'{accuracy:.2f}'  # 将准确率格式化为带两位小数的字符串
    print(f'Accuracy at epoch {epoch + 1}: {formatted_accuracy} %')
    accuracy_values.append(formatted_accuracy)  # 保存带两位小数的准确率
    epoch_numbers.append(epoch + 1)
```



## 6. 结果

准确率来看均在70%以上，最好的达到73%

| batch_size | 优化器 | LR    | 图                                                           | 最好epoch  | 准确率    |
| ---------- | ------ | ----- | ------------------------------------------------------------ | ---------- | --------- |
| 128        | SGD    | 0.005 | ![image-20231026152855189](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026152855189.png) | 87         | 72.05     |
| 64         | SGD    | 0.005 | ![image-20231026152933905](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026152933905.png) | 60, 66, 75 | **73.08** |
| 32         | SGD    | 0.005 | ![image-20231026153002767](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153002767.png) | 5          | 71.81     |
| 128        | SGD    | 0.001 | ![image-20231026153047744](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153047744.png) | 46         | 70.98     |
| 64         | SGD    | 0.001 | ![image-20231026153124128](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153124128.png) | 41         | 71.97     |
| 32         | SGD    | 0.001 | ![image-20231026153151392](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153151392.png) | 89         | 72.63     |
| 128        | Adam   | 0.001 | ![image-20231026153321641](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153321641.png) | 5          | 71.1      |
| 64         | Adam   | 0.001 | ![image-20231026153344996](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153344996.png) | 6          | 71.08     |
| 32         | Adam   | 0.001 | ![image-20231026153402072](211250097_LeNet_%E4%B8%81%E6%99%9F%E5%85%83/image-20231026153402072.png) | 5          | 70.05     |

### 分析

从准确率变化曲线来看，明显SGD优化器的效果要好于Adam

- SGD（随机梯度下降）优化器：
  SGD是一种基本的优化算法，在每个batch中根据当前样本计算梯度并更新模型参数。SGD的特点是简单直接，每次迭代只使用一个样本进行梯度计算和参数更新，因此计算开销较小。然而，这种随机性也可能导致优化过程中出现一些波动，尤其是在训练数据集较小或噪声较多的情况下。但是，通过适当的学习率调整和较多的迭代次数，SGD可以在合理的时间内收敛到较好的解。
- Adam优化器：
  Adam是一种自适应学习率的优化算法，结合了动量法和自适应学习率机制。它可以根据梯度的一阶矩估计（均值）和二阶矩估计（方差）自适应地调整学习率，从而更好地适应不同参数的变化情况。Adam在很多情况下表现良好，并且具有较快的收敛速度。然而，对于某些数据集和模型结构，Adam可能会在训练过程中过早收敛或陷入局部最优解，尤其是在学习率设置不当时。这可能导致准确率变化曲线的性能较差。



## 7. 参考链接

官方demo：

[Training a Classifier — PyTorch Tutorials 2.1.0+cu121 documentation](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)

查找PyTorch API：

https://pytorch.org/docs/stable/index.html



